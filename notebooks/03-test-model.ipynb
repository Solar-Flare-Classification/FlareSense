{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed working directory to: /Users/patrickschuermann/Documents/GitHub/FlareSense\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")\n",
    "print(f\"Changed working directory to: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import mlflow\n",
    "import dagshub\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import src.utils.data as data\n",
    "import pytorch_lightning as pl\n",
    "import torchvision.models as models\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchmetrics.classification import BinaryPrecision, BinaryRecall\n",
    "\n",
    "mlflow.pytorch.autolog()\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50BinaryClassifier(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resnet50 = models.resnet50()\n",
    "        self.resnet50.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        num_features = self.resnet50.fc.in_features\n",
    "        self.resnet50.fc = nn.Linear(num_features, 1)\n",
    "\n",
    "        # Deaktivieren der Gradienten für alle Layers außer dem letzten\n",
    "        for param in self.resnet50.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.resnet50.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "        # Initialisierung der Metriken\n",
    "        self.precision = BinaryPrecision(threshold=0.5)\n",
    "        self.recall = BinaryRecall(threshold=0.5)\n",
    "\n",
    "        # Initialisieren der Listen\n",
    "        self.test_labels = []\n",
    "        self.test_preds = []\n",
    "        self.val_outputs = []\n",
    "        self.val_labels = []\n",
    "        self.val_preds = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet50(x)\n",
    "\n",
    "    def __step(self, batch):\n",
    "        images, info = batch\n",
    "\n",
    "        binary_labels = [0 if label == \"no_burst\" else 1 for label in info['label']]\n",
    "        binary_labels = torch.tensor(binary_labels).float().view(-1, 1)\n",
    "        binary_labels = binary_labels.to(images.device)\n",
    "\n",
    "        outputs = self(images)\n",
    "        return outputs, binary_labels\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        outputs, binary_labels = self.__step(batch)\n",
    "        loss = nn.BCEWithLogitsLoss()(outputs, binary_labels)\n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        outputs, binary_labels = self.__step(batch)\n",
    "        loss = nn.BCEWithLogitsLoss()(outputs, binary_labels)\n",
    "\n",
    "        # Labels und Vorhersagen für spätere Verwendung speichern\n",
    "        self.test_labels.append(binary_labels)\n",
    "        self.test_preds.append(outputs)\n",
    "\n",
    "        # Berechnen und protokollieren des Verlusts\n",
    "        self.log(\n",
    "            \"test_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        # Konvertieren der gesammelten Daten in einzelne Tensoren\n",
    "        test_labels = torch.cat(self.test_labels, dim=0)\n",
    "        test_preds = torch.cat(self.test_preds, dim=0)\n",
    "\n",
    "        # Berechnen der Metriken\n",
    "        precision = self.precision(test_preds, test_labels)\n",
    "        recall = self.recall(test_preds, test_labels)\n",
    "\n",
    "        # Protokollieren der Metriken\n",
    "        self.log(\"test_precision\", precision)\n",
    "        self.log(\"test_recall\", recall)\n",
    "\n",
    "        # Bereinigen der Listen für die nächste Epoche\n",
    "        self.test_labels = []\n",
    "        self.test_preds = []\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        outputs, binary_labels = self.__step(batch)\n",
    "\n",
    "        # Labels und Vorhersagen für die spätere Verwendung speichern\n",
    "        predictions = (outputs >= 0.5).int()\n",
    "        self.val_labels.append(binary_labels.int())\n",
    "        self.val_preds.append(predictions)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        # Alle Validierungsdaten wurden gesammelt, und wir sind am Ende der Epoche.\n",
    "        val_labels = torch.cat(self.val_labels, dim=0)\n",
    "        val_preds = torch.cat(self.val_preds, dim=0)\n",
    "\n",
    "        # Berechnen der Metriken\n",
    "        precision = self.precision(val_preds, val_labels)\n",
    "        recall = self.recall(val_preds, val_labels)\n",
    "\n",
    "        # Protokollieren der Metriken\n",
    "        self.log(\"val_precision\", precision)\n",
    "        self.log(\"val_recall\", recall)\n",
    "\n",
    "        # Vergessen Sie nicht, die Listen für die nächste Validierungsrunde zu leeren\n",
    "        self.val_labels = []\n",
    "        self.val_preds = []\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.resnet50.fc.parameters(), lr=0.001, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/patrickschuermann/.local/share/virtualenvs/Deep_Learning-EdiEON_k/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "/Users/patrickschuermann/.local/share/virtualenvs/Deep_Learning-EdiEON_k/lib/python3.9/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "\n",
      "  | Name      | Type            | Params\n",
      "----------------------------------------------\n",
      "0 | resnet50  | ResNet          | 23.5 M\n",
      "1 | precision | BinaryPrecision | 0     \n",
      "2 | recall    | BinaryRecall    | 0     \n",
      "----------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.015    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f987a30c36ed4b92b16852949e424067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patrickschuermann/.local/share/virtualenvs/Deep_Learning-EdiEON_k/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
      "/Users/patrickschuermann/.local/share/virtualenvs/Deep_Learning-EdiEON_k/lib/python3.9/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/Users/patrickschuermann/.local/share/virtualenvs/Deep_Learning-EdiEON_k/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc44487e1ac84570968ef1999586b6cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06c1a79941c34e0581888fd16a0d6c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "2023/11/07 10:27:36 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/patrickschuermann/.local/share/virtualenvs/Deep_Learning-EdiEON_k/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n",
      "/Users/patrickschuermann/.local/share/virtualenvs/Deep_Learning-EdiEON_k/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'test_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b22f149c9c4b48e5ab514eb464d71ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patrickschuermann/.local/share/virtualenvs/Deep_Learning-EdiEON_k/lib/python3.9/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 64. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/Users/patrickschuermann/.local/share/virtualenvs/Deep_Learning-EdiEON_k/lib/python3.9/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 10. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_loss_epoch      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.12003026902675629    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_loss_epoch     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.12003026902675629   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Erstellen Sie eine Instanz des Modells\n",
    "model = ResNet50BinaryClassifier()\n",
    "data_folder_path = \"data/raw/burst_images/\"\n",
    "\n",
    "data_module = data.ECallistoDataModule(\n",
    "    data_folder=data_folder_path,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((193, 240), antialias=True),\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "    ),\n",
    "    batch_size=64,\n",
    "    num_workers=16,\n",
    "    val_ratio=0.15,\n",
    "    test_ratio=0.15,\n",
    "    split_by_date=True,\n",
    "    filter_instruments=[\"australia_assa_02\"],\n",
    ")\n",
    "data_module.setup()\n",
    "\n",
    "dagshub.init(\"FlareSense\", \"FlareSense\", mlflow=True)\n",
    "mlflow.start_run()\n",
    "# Erstellen Sie einen Trainer für das Training\n",
    "trainer = pl.Trainer(max_epochs=1)\n",
    "\n",
    "# Starten Sie das Training\n",
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=data_module.train_dataloader(),\n",
    "    val_dataloaders=data_module.val_dataloader(),\n",
    ")\n",
    "\n",
    "# Starten Sie die Tests\n",
    "trainer.test(model, dataloaders=data_module.test_dataloader())\n",
    "\n",
    "# Speichern Sie das Modell\n",
    "torch.save(model.state_dict(), \"models/ResNet50BinaryClassifier.pth\")\n",
    "\n",
    "# Beenden Sie die MLflow-Sitzung\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6e05621076ca54fd44c7c0ce1b6a0f390ce58f91d2fe1d180f4996db114adea7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
