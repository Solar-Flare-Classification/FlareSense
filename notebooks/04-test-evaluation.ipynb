{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed working directory to: /home/jovyan/work/FlareSense\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")\n",
    "print(f\"Changed working directory to: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pydantic/_internal/_fields.py:128: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/pydantic/_internal/_config.py:317: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import mlflow\n",
    "import dagshub\n",
    "import numpy as np\n",
    "import torchmetrics\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import src.utils.data as data\n",
    "import pytorch_lightning as pl\n",
    "import torchvision.models as models\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from torchmetrics.classification import BinaryPrecision, BinaryRecall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8623c3eee14b17862c70f34ba9d468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_id = \"115ecd0ffec84cbfbfb6431b4d879464\" # Change to model\n",
    "\n",
    "mlflow.set_tracking_uri('https://dagshub.com/FlareSense/Flaresense.mlflow')\n",
    "model = mlflow.pytorch.load_model(f\"runs:/{run_id}/model/\").to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_path = \"data/raw/burst_images/\"\n",
    "\n",
    "data_module = data.ECallistoDataModule(\n",
    "    data_folder=data_folder_path,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((193, 240), antialias=True),\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "    ),\n",
    "    batch_size=32,\n",
    "    num_workers=0,\n",
    "    val_ratio=0.2,\n",
    "    test_ratio=0.2,\n",
    "    split_by_date=True,\n",
    "    filter_instruments=[\"australia_assa_02\"],    \n",
    ")\n",
    "data_module.setup()\n",
    "\n",
    "val_loader = data_module.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d53d9efa981b4023916131fcde5350fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_labels_list = []\n",
    "val_preds_list = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_loader):\n",
    "        images, info = batch\n",
    "        images = images.to(device)\n",
    "        binary_labels = [0 if label == \"no_burst\" else 1 for label in info['label']]\n",
    "        binary_labels = torch.tensor(binary_labels).int().view(-1, 1)\n",
    "        binary_labels = binary_labels.to(device)\n",
    "        \n",
    "        outputs = model(images.expand(-1, 3, -1, -1))\n",
    "        predictions = (outputs >= 0.5).int()\n",
    "        \n",
    "        val_labels_list.append(binary_labels)\n",
    "        val_preds_list.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_preds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alle Validierungsdaten wurden gesammelt\n",
    "val_labels = torch.cat(val_labels_list, dim=0)\n",
    "val_preds = torch.cat(val_preds_list, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3885,    6],\n",
       "        [  49,   94]], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialisieren Sie den ConfusionMatrix-Metriken von torchmetrics\n",
    "confmat_metric = torchmetrics.ConfusionMatrix(num_classes=2, task=\"binary\").to(device)\n",
    "confmat_metric(val_preds, val_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "6e05621076ca54fd44c7c0ce1b6a0f390ce58f91d2fe1d180f4996db114adea7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
