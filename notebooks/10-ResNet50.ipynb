{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed working directory to: /Users/gabriel.torres/Nextcloud/Development/Pro5D/FlareSense\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")\n",
    "print(f\"Changed working directory to: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import mlflow\n",
    "import dagshub\n",
    "import torchmetrics\n",
    "import src.utils.data15min as data\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "from torchvision import transforms\n",
    "from tqdm.notebook import tqdm\n",
    "from src.models.ResNet50BinaryClassifier import ResNet50BinaryClassifier\n",
    "\n",
    "mlflow.pytorch.autolog()\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "806ee23db0184b33b0da1347a9d3587c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Australia-ASSA_62.zip\n"
     ]
    }
   ],
   "source": [
    "data_folder_path = \"data/raw/exported/\"\n",
    "\n",
    "# download data if needed\n",
    "snapshot_download(\n",
    "    \"StellarMilk/ecallisto-bursts\",\n",
    "    repo_type=\"dataset\",\n",
    "    allow_patterns=[\"*62.zip\", \"*.csv\"],\n",
    "    local_dir=data_folder_path,\n",
    "    revision=\"main\",\n",
    ")\n",
    "\n",
    "# unzip data if needed\n",
    "instruments = [file for file in os.listdir(data_folder_path) if file.endswith(\".zip\")]\n",
    "for instrument in instruments:\n",
    "    if os.path.exists(f\"{data_folder_path}{instrument[:-4]}\"):\n",
    "        print(f\"Skipping {instrument}\")\n",
    "        continue\n",
    "    print(f\"Unzipping {instrument}\")\n",
    "    !unzip -q {data_folder_path}{instrument} -d {data_folder_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50BinaryClassifier(lr=1e-4, weight_decay=1e-2)\n",
    "\n",
    "data_module = data.ECallistoDataModule(\n",
    "    data_folder=data_folder_path,\n",
    "    batch_size=64,\n",
    "    num_workers=0,\n",
    "    val_ratio=0.15,\n",
    "    test_ratio=0.15,\n",
    "    img_size=(224, 224),\n",
    "    use_augmented_data=True,\n",
    "    filter_instruments=[\"Australia-ASSA_62\"],\n",
    "    seed=0,\n",
    ")\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset:\n",
      "no_burst    21353\n",
      "III         15418\n",
      "V             265\n",
      "II            221\n",
      "VI            182\n",
      "IV             24 \n",
      "\n",
      "Validation dataset:\n",
      "no_burst    4581\n",
      "III          283\n",
      "II             8\n",
      "V              4\n",
      "VI             2 \n",
      "\n",
      "Test dataset:\n",
      "no_burst    4588\n",
      "III          273\n",
      "V              7\n",
      "VI             5\n",
      "II             3\n",
      "IV             1\n"
     ]
    }
   ],
   "source": [
    "print(\"Train dataset:\")\n",
    "print(data_module.train_dataset.metadata.type.value_counts().to_string(header=False), \"\\n\")\n",
    "\n",
    "print(\"Validation dataset:\")\n",
    "print(data_module.val_dataset.metadata.type.value_counts().to_string(header=False), \"\\n\")\n",
    "\n",
    "print(\"Test dataset:\")\n",
    "print(data_module.test_dataset.metadata.type.value_counts().to_string(header=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 50 batch(es). Logging and checkpointing is suppressed.\n",
      "2023/12/26 23:00:34 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '304f8e53ca924d87a6c732fc0fc16c96', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name      | Type            | Params\n",
      "----------------------------------------------\n",
      "0 | precision | BinaryPrecision | 0     \n",
      "1 | recall    | BinaryRecall    | 0     \n",
      "2 | resnet50  | ResNet          | 23.5 M\n",
      "----------------------------------------------\n",
      "22.1 M    Trainable params\n",
      "1.4 M     Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.040    Total estimated model params size (MB)\n",
      "/opt/homebrew/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/opt/homebrew/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bb0079331fd452bb1a549b3d5887b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "662b130778f5412bb48489d666cd0366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=50` reached.\n",
      "2023/12/26 23:02:52 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/opt/homebrew/Cellar/python@3.11/3.11.6/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n",
      "/opt/homebrew/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86e106e2876a46cc8e583eeafb3c617e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.0, 'test_precision': 0.0, 'test_recall': 0.0}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dagshub.init(\"FlareSense\", \"FlareSense\", mlflow=True)\n",
    "# mlflow.start_run()\n",
    "\n",
    "# mlflow.log_params(\n",
    "#    {\n",
    "#        \"model\": \"ResNet50\",\n",
    "#        \"batch_size\": data_module.batch_size,\n",
    "#        \"val_ratio\": data_module.val_ratio,\n",
    "#        \"test_ratio\": data_module.test_ratio,\n",
    "#        \"min_factor_val_test\": data_module.min_factor_val_test,\n",
    "#        \"max_factor_val_test\": data_module.max_factor_val_test,\n",
    "#        \"noburst_to_burst_ratio\": data_module.noburst_to_burst_ratio,\n",
    "#        \"split_by_date\": data_module.split_by_date,\n",
    "#        \"filter_instruments\": data_module.filter_instruments,\n",
    "#    }\n",
    "# )\n",
    "\n",
    "# run_id = mlflow.active_run().info.run_id\n",
    "# print(f\"Run ID: {run_id}\")\n",
    "# print(f\"Link: https://dagshub.com/FlareSense/FlareSense/experiments/#/experiment/m_{run_id}\")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=10, log_every_n_steps=1, fast_dev_run=50)\n",
    "\n",
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=data_module.train_dataloader(),\n",
    "    val_dataloaders=data_module.val_dataloader(),\n",
    ")\n",
    "\n",
    "trainer.test(model, dataloaders=data_module.test_dataloader())\n",
    "\n",
    "# mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
