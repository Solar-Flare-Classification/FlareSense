{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x13850fc90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomParquetDataset(Dataset):\n",
    "    def __init__(self, data_folder, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_folder (string): Pfad zum Ordner mit den Parquet-Dateien.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "\n",
    "        # Liste der Parquet-Dateien\n",
    "        self.file_paths = [os.path.join(data_folder, f) for f in os.listdir(data_folder) if f.endswith('.parquet')]\n",
    "        self.folder_number = self.extract_folder_number(data_folder)\n",
    "        \n",
    "        # Lesen der Daten und Kombinieren in einem großen DataFrame\n",
    "        self.data = pd.concat([pd.read_parquet(file) for file in self.file_paths])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # Zeitstempel extrahieren und in einen String konvertieren\n",
    "        timestamp = str(self.data.index[idx])\n",
    "\n",
    "        # Daten für den aktuellen Index extrahieren\n",
    "        sample = self.data.iloc[idx].values  # Werte der Zeile als Array\n",
    "\n",
    "        sample_tensor = torch.tensor(sample, dtype=torch.float)\n",
    "\n",
    "        if self.transform:\n",
    "            sample_tensor = self.transform(sample_tensor)\n",
    "\n",
    "        return sample_tensor, timestamp, self.folder_number\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_folder_number(folder_path):\n",
    "        \"\"\"\n",
    "        Extrahiert die Zahl aus dem Ordnernamen, falls vorhanden.\n",
    "        \"\"\"\n",
    "        folder_name = os.path.basename(folder_path)\n",
    "        try:\n",
    "            # Versuch, den Ordnernamen in eine Zahl umzuwandeln\n",
    "            return int(folder_name)\n",
    "        except ValueError:\n",
    "            # Wenn der Ordnernamen keine Zahl ist, geben Sie 0 zurück\n",
    "            return 0\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pfad zum 'data' Ordner\n",
    "data_folder_path = '../../data/raw/ecallisto_ng_unzipped/2'  # Bitte passen Sie diesen Pfad entsprechend an.\n",
    "\n",
    "# Erstellen Sie eine Instanz Ihres benutzerdefinierten Datensatzes\n",
    "custom_dataset = CustomParquetDataset(data_folder=data_folder_path)\n",
    "\n",
    "# Aufteilen des Datensatzes in Trainings- und Testsets\n",
    "train_size = int(0.8 * len(custom_dataset))\n",
    "test_size = len(custom_dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(custom_dataset, [train_size, test_size])\n",
    "\n",
    "# Erstellen von DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get timestamps.\n",
    "Find the closest one to a full minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2021-10-09 06:46:59.701000',\n",
       " '2021-11-02 02:22:10.032000',\n",
       " '2021-10-09 06:43:12.670000',\n",
       " '2021-10-09 06:41:59.670000',\n",
       " '2021-10-09 06:41:24.920000',\n",
       " '2021-09-28 06:28:30.927000',\n",
       " '2021-09-08 00:09:16.222000',\n",
       " '2021-08-28 05:11:07.017000',\n",
       " '2021-09-17 04:18:20.583000',\n",
       " '2021-10-09 06:36:55.670000',\n",
       " '2021-11-01 01:43:32.108000',\n",
       " '2021-05-22 03:06:04.473000',\n",
       " '2021-11-02 02:24:38.532000',\n",
       " '2021-10-09 06:37:43.170000',\n",
       " '2021-11-01 01:31:31.858000',\n",
       " '2021-10-09 06:50:27.201000',\n",
       " '2021-08-28 05:11:46.517000',\n",
       " '2021-11-02 02:24:10.782000',\n",
       " '2021-10-09 06:51:10.701000',\n",
       " '2021-10-09 06:41:18.170000')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch = next(iter(train_loader))\n",
    "\n",
    "batch_data, batch_timestamps, batch_folder_numbers = first_batch\n",
    "\n",
    "batch_timestamps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take index of the closest one to full minute and get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First data in batch: tensor([156., 162., 172., 169., 154., 149., 153., 150., 175., 160., 153., 158.,\n",
      "        149., 154., 155., 151., 153., 153., 161., 180., 157., 153., 153., 151.,\n",
      "        152., 152., 152., 152., 153., 152., 154., 155., 157., 158., 158., 157.,\n",
      "        157., 159., 158., 158., 158., 158., 161., 160., 161., 162., 164., 164.,\n",
      "        164., 164., 165., 165., 166., 167., 168., 170., 170., 168., 167., 167.,\n",
      "        168., 167., 168., 166., 166., 165., 165., 165., 164., 165., 164., 164.,\n",
      "        163., 164., 163., 162., 162., 164., 164., 164., 162., 164., 164., 163.,\n",
      "        162., 161., 162., 162., 163., 163., 163., 163., 163., 163., 162., 161.,\n",
      "        160., 159., 160., 159., 158., 158., 158., 157., 157., 156., 156., 155.,\n",
      "        156., 157., 156., 156., 156., 156., 155., 155., 154., 155., 163., 157.,\n",
      "        158., 157., 156., 156., 154., 152., 153., 153., 156., 153., 153., 155.,\n",
      "        156., 153., 154., 154., 154., 154., 153., 151., 151., 149., 151., 150.,\n",
      "        150., 151., 150., 150., 150., 150., 149., 150., 150., 150., 151., 151.,\n",
      "        152., 152., 153., 153., 152., 151., 150., 149., 149., 150., 149., 151.,\n",
      "        150., 149., 147., 146., 146., 146., 146., 145., 144., 144., 146., 144.,\n",
      "        145., 145., 146., 148., 148., 147., 148., 146., 145., 146., 145., 143.,\n",
      "        143.])\n",
      "Timestamp of first data: 2021-10-09 06:46:59.701000\n",
      "Folder number of  data: tensor(2)\n"
     ]
    }
   ],
   "source": [
    "first_data_in_batch = batch_data[0]\n",
    "first_timestamp_in_batch = batch_timestamps[0]\n",
    "first_folder_number_in_batch = batch_folder_numbers[0]\n",
    "\n",
    "print(\"First data in batch:\", first_data_in_batch)\n",
    "print(\"Timestamp of first data:\", first_timestamp_in_batch)\n",
    "print(\"Folder number of  data:\", first_folder_number_in_batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the corresponding parquet file and check values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>15</th>\n",
       "      <th>15.312999725341797</th>\n",
       "      <th>15.687999725341797</th>\n",
       "      <th>16.062999725341797</th>\n",
       "      <th>16.437999725341797</th>\n",
       "      <th>16.812999725341797</th>\n",
       "      <th>17.187999725341797</th>\n",
       "      <th>17.562999725341797</th>\n",
       "      <th>17.937999725341797</th>\n",
       "      <th>18.312999725341797</th>\n",
       "      <th>...</th>\n",
       "      <th>83.56300354003906</th>\n",
       "      <th>83.93800354003906</th>\n",
       "      <th>84.31300354003906</th>\n",
       "      <th>84.68800354003906</th>\n",
       "      <th>85.06300354003906</th>\n",
       "      <th>85.43800354003906</th>\n",
       "      <th>85.81300354003906</th>\n",
       "      <th>86.18800354003906</th>\n",
       "      <th>86.56300354003906</th>\n",
       "      <th>86.93800354003906</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-10-09 06:46:59.701</th>\n",
       "      <td>156</td>\n",
       "      <td>162</td>\n",
       "      <td>172</td>\n",
       "      <td>169</td>\n",
       "      <td>154</td>\n",
       "      <td>149</td>\n",
       "      <td>153</td>\n",
       "      <td>150</td>\n",
       "      <td>175</td>\n",
       "      <td>160</td>\n",
       "      <td>...</td>\n",
       "      <td>148</td>\n",
       "      <td>148</td>\n",
       "      <td>147</td>\n",
       "      <td>148</td>\n",
       "      <td>146</td>\n",
       "      <td>145</td>\n",
       "      <td>146</td>\n",
       "      <td>145</td>\n",
       "      <td>143</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-09 06:46:59.951</th>\n",
       "      <td>156</td>\n",
       "      <td>163</td>\n",
       "      <td>173</td>\n",
       "      <td>169</td>\n",
       "      <td>157</td>\n",
       "      <td>150</td>\n",
       "      <td>154</td>\n",
       "      <td>151</td>\n",
       "      <td>176</td>\n",
       "      <td>161</td>\n",
       "      <td>...</td>\n",
       "      <td>148</td>\n",
       "      <td>148</td>\n",
       "      <td>148</td>\n",
       "      <td>147</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>145</td>\n",
       "      <td>143</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          15  15.312999725341797  15.687999725341797  \\\n",
       "datetime                                                               \n",
       "2021-10-09 06:46:59.701  156                 162                 172   \n",
       "2021-10-09 06:46:59.951  156                 163                 173   \n",
       "\n",
       "                         16.062999725341797  16.437999725341797  \\\n",
       "datetime                                                          \n",
       "2021-10-09 06:46:59.701                 169                 154   \n",
       "2021-10-09 06:46:59.951                 169                 157   \n",
       "\n",
       "                         16.812999725341797  17.187999725341797  \\\n",
       "datetime                                                          \n",
       "2021-10-09 06:46:59.701                 149                 153   \n",
       "2021-10-09 06:46:59.951                 150                 154   \n",
       "\n",
       "                         17.562999725341797  17.937999725341797  \\\n",
       "datetime                                                          \n",
       "2021-10-09 06:46:59.701                 150                 175   \n",
       "2021-10-09 06:46:59.951                 151                 176   \n",
       "\n",
       "                         18.312999725341797  ...  83.56300354003906  \\\n",
       "datetime                                     ...                      \n",
       "2021-10-09 06:46:59.701                 160  ...                148   \n",
       "2021-10-09 06:46:59.951                 161  ...                148   \n",
       "\n",
       "                         83.93800354003906  84.31300354003906  \\\n",
       "datetime                                                        \n",
       "2021-10-09 06:46:59.701                148                147   \n",
       "2021-10-09 06:46:59.951                148                148   \n",
       "\n",
       "                         84.68800354003906  85.06300354003906  \\\n",
       "datetime                                                        \n",
       "2021-10-09 06:46:59.701                148                146   \n",
       "2021-10-09 06:46:59.951                147                146   \n",
       "\n",
       "                         85.43800354003906  85.81300354003906  \\\n",
       "datetime                                                        \n",
       "2021-10-09 06:46:59.701                145                146   \n",
       "2021-10-09 06:46:59.951                146                146   \n",
       "\n",
       "                         86.18800354003906  86.56300354003906  \\\n",
       "datetime                                                        \n",
       "2021-10-09 06:46:59.701                145                143   \n",
       "2021-10-09 06:46:59.951                145                143   \n",
       "\n",
       "                         86.93800354003906  \n",
       "datetime                                    \n",
       "2021-10-09 06:46:59.701                143  \n",
       "2021-10-09 06:46:59.951                143  \n",
       "\n",
       "[2 rows x 193 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"../../data/raw/ecallisto_ng_unzipped/2/australia_assa_02_2021-10-09 06-46-00_2021-10-09 06-47-00_None_None.parquet\", engine='auto')\n",
    "df.tail(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count all observations (rows) in folder 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesamtanzahl der Zeilen in allen Parquet-Dateien: 22550\n"
     ]
    }
   ],
   "source": [
    "directory_path = '../../data/raw/ecallisto_ng_unzipped/2'\n",
    "\n",
    "parquet_files = [f for f in os.listdir(directory_path) if f.endswith('.parquet')]\n",
    "\n",
    "total_rows = 0\n",
    "\n",
    "for file_name in parquet_files:\n",
    "    file_path = os.path.join(directory_path, file_name)\n",
    "    \n",
    "    df = pd.read_parquet(file_path, engine='auto')\n",
    "    \n",
    "    num_rows = len(df)\n",
    "    \n",
    "    total_rows += num_rows\n",
    "\n",
    "print(f\"Gesamtanzahl der Zeilen in allen Parquet-Dateien: {total_rows}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and check with number of rows in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22550"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(custom_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "269cf2f92329ade5410ea106c9b830a2a3a4b403f68305fdd35f54dc4888a741"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
